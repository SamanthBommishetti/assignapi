# -*- coding: utf-8 -*-
"""3. Loss & Recovery Analysis

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_euMatwpcRcX8drIPJqhjOxyG4flZj56
"""

import pandas as pd
from datetime import datetime
import clickhouse_connect
import os

# --- Config ---
clickhouse_host = "57.159.27.80"
clickhouse_port = 8123
clickhouse_database = "fmac_db"
clickhouse_user = "fmacadmin"
clickhouse_password = "fmac*2025"


# --- Initialize Client ---
def initialize_clickhouse_client():
    """Initialize and return the ClickHouse client."""
    try:
        client = clickhouse_connect.get_client(
            host=clickhouse_host,
            port=clickhouse_port,
            username=clickhouse_user,
            password=clickhouse_password,
            database=clickhouse_database
        )
        print("ClickHouse client initialized successfully.")
        return client
    except Exception as e:
        print(f"❌ Failed to initialize ClickHouse client: {e}")
        raise


# === Loss & Recovery Analytics Queries (3.1–3.7) ===
queries = [
    ("total_actual_loss_and_ratio", """
        SELECT
            SUM(actual_loss) AS total_loss,
            SUM(actual_loss) / NULLIF(SUM(zero_balance_removal_upb), 0) AS loss_ratio
        FROM performance_updated_2025_ctas
        WHERE zero_balance_code IS NOT NULL
    """, "What is the total actual loss and loss ratio?",
       "Total actual loss and ratio", "single_value", "single_value"),

    ("total_recoveries", """
        SELECT
            SUM(mi_recoveries) AS total_mi_recoveries,
            SUM(non_mi_recoveries) AS total_non_mi_recoveries,
            SUM(mi_recoveries + non_mi_recoveries) AS total_recoveries
        FROM performance_updated_2025_ctas
        WHERE zero_balance_code IS NOT NULL
    """, "What are the total MI and non-MI recoveries?",
       "Total recoveries summary", "bar", "bar,pie,histogram"),

    ("average_loss_per_resolved_loan", """
        SELECT
            AVG(actual_loss) AS avg_loss_per_loan
        FROM performance_updated_2025_ctas
        WHERE zero_balance_code IS NOT NULL
    """, "What is the average loss per resolved loan?",
       "Average loss per resolved loan", "single_value", "single_value"),

    ("expense_breakdown_for_resolved_loans", """
        SELECT
            SUM(legal_costs) AS legal_costs,
            SUM(maintenance_preservation_costs) AS maintenance_costs,
            SUM(taxes_insurance) AS tax_costs,
            SUM(misc_expenses) AS misc_costs
        FROM performance_updated_2025_ctas
        WHERE zero_balance_code IS NOT NULL
    """, "What are the main expense categories for resolved loans?",
       "Expense breakdown for resolved loans", "bar", "bar,scatter,line"),

    ("monthly_loss_trend", """
        SELECT
            DATE_TRUNC('month', zero_balance_effective_date) AS loss_month,
            SUM(actual_loss) AS monthly_loss
        FROM performance_updated_2025_ctas
        WHERE zero_balance_code IS NOT NULL
        GROUP BY loss_month
        ORDER BY loss_month
    """, "What is the monthly trend in actual losses?",
       "Monthly loss trend", "line", "line,bar,scatter"),

    ("loss_by_delinquency_bucket", """
        SELECT
            current_loan_delinquency_status,
            AVG(actual_loss) AS avg_loss
        FROM performance_updated_2025_ctas
        WHERE zero_balance_code IS NOT NULL
        GROUP BY current_loan_delinquency_status
    """, "How do losses vary by delinquency bucket?",
       "Loss by delinquency bucket", "bar", "bar,histogram,pie"),

    ("loss_by_loan_age_bucket", """
        SELECT
            CASE
                WHEN loan_age < 12 THEN '0–1 Year'
                WHEN loan_age BETWEEN 12 AND 60 THEN '1–5 Years'
                ELSE '5+ Years'
            END AS loan_age_bucket,
            SUM(actual_loss) AS total_loss
        FROM performance_updated_2025_ctas
        WHERE zero_balance_code IS NOT NULL
        GROUP BY loan_age_bucket
    """, "How do losses vary by loan vintage or age?",
       "Loss by loan age bucket", "bar", "bar,pie,scatter")
]


# === Create Metadata ===
now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

def run_loss_recovery_analysis_queries():
    client = initialize_clickhouse_client()
    output_dir = "general_out_csvfiles"
    output_save_dir = "app/general_out_csvfiles"
    os.makedirs(output_dir, exist_ok=True)
    os.makedirs(output_save_dir, exist_ok=True)
    results = []
    for i, (name, sql, q_str, desc, chart, suggested_chart) in enumerate(queries, start=1):
        try:
            result = client.query(sql)
            result_df = pd.DataFrame(result.result_rows, columns=result.column_names)
            csv_filename = f"general_query_{i}_{name}.csv"
            csv_save_path = os.path.join(output_save_dir, csv_filename)
            result_df.to_csv(csv_save_path, index=False, encoding="utf-8")
            csv_table_path = os.path.join(output_dir, csv_filename)
            results.append({
                "query_sql_string": sql.strip(),
                "query_str": q_str,
                "description": desc,
                "csv_file_path": csv_table_path,
                "chart_type": chart,
                "suggested_chart_types": suggested_chart
            })
            print(f"Query {i} saved: {csv_save_path}")
        except Exception as e:
            print(f"Failed query {i}: {e}")
    client.close()
    return results